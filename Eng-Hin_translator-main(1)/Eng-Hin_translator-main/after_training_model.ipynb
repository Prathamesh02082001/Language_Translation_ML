{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = load_model(r'C:/Users/Niraj/Desktop/ML_PROJECT/nmt_model1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_input_sequence(input_sequence, max_length_src, input_token_index):\n",
    "    input_seq = np.zeros((1, max_length_src), dtype='float32')\n",
    "    for t, word in enumerate(input_sequence.split()):\n",
    "        input_seq[0, t] = input_token_index.get(word, 0) \n",
    "    return input_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_output(input_sequence, model, max_length_tar, target_token_index, reverse_target_char_index):\n",
    "    target_seq = np.zeros((1, max_length_tar), dtype='float32')\n",
    "    target_seq[0, 0] = target_token_index['START_']\n",
    "\n",
    "    stop_condition = False\n",
    "    t = 0\n",
    "\n",
    "    while not stop_condition:\n",
    "        output_tokens = model.predict([input_sequence, target_seq])\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index.get(int(sampled_token_index), 'UNK')\n",
    "\n",
    "        if sampled_char == '_END' or t >= max_length_tar - 1:\n",
    "            stop_condition = True\n",
    "        else:\n",
    "            target_seq[0, t + 1] = sampled_token_index\n",
    "            t += 1\n",
    "\n",
    "    predicted_sentence = ' '.join([reverse_target_char_index.get(int(token), 'UNK') for token in target_seq[0] if int(token) != 0])\n",
    "    return predicted_sentence.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Input Sentence: that its a time machine in a certain sense\n",
      "Predicted Output: START_ उसे कुछ मायनों में टाईम मशीन जैसा बना देता है\n"
     ]
    }
   ],
   "source": [
    "\n",
    "max_length_src = 20\n",
    "\n",
    "\n",
    "\n",
    "input_sentence = \"that its a time machine in a certain sense\"\n",
    "\n",
    "input_sequence = preprocess_input_sequence(input_sentence, max_length_src, input_token_index)\n",
    "\n",
    "\n",
    "predicted_output = predict_output(input_sequence, model, max_length_tar, target_token_index, reverse_target_char_index)\n",
    "\n",
    "\n",
    "print(f\"Input Sentence: {input_sentence}\")\n",
    "print(f\"Predicted Output: {predicted_output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum length of Hindi Sentence  20\n",
      "maximum length of English Sentence  20\n",
      "WARNING:tensorflow:From c:\\Users\\Niraj\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, None)]               0         []                            \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)        [(None, None)]               0         []                            \n",
      "                                                                                                  \n",
      " embedding (Embedding)       (None, None, 300)            4209300   ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)     (None, None, 300)            5262300   ['input_2[0][0]']             \n",
      "                                                                                                  \n",
      " lstm (LSTM)                 [(None, 300),                721200    ['embedding[0][0]']           \n",
      "                              (None, 300),                                                        \n",
      "                              (None, 300)]                                                        \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)               [(None, None, 300),          721200    ['embedding_1[0][0]',         \n",
      "                              (None, 300),                           'lstm[0][1]',                \n",
      "                              (None, 300)]                           'lstm[0][2]']                \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, None, 17541)          5279841   ['lstm_1[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 16193841 (61.77 MB)\n",
      "Trainable params: 16193841 (61.77 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "\n",
    "import os\n",
    "import string\n",
    "from string import digits\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import re\n",
    "\n",
    "import seaborn as sns\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Input, LSTM, Embedding, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.max_colwidth', 1)\n",
    "\n",
    "\n",
    "lines=pd.read_csv(r\"C:/Users/Niraj/Downloads/Hindi_English_Truncated_Corpus.csv\",encoding='utf-8')\n",
    "\n",
    "lines['source'].value_counts()\n",
    "\n",
    "\n",
    "lines=lines[lines['source']=='ted']\n",
    "\n",
    "\n",
    "lines.head(20)\n",
    "\n",
    "pd.isnull(lines).sum()\n",
    "\n",
    "lines=lines[~pd.isnull(lines['english_sentence'])]\n",
    "\n",
    "lines.drop_duplicates(inplace=True)\n",
    "\n",
    "lines=lines.sample(n=25000,random_state=42)\n",
    "lines.shape\n",
    "\n",
    "lines['english_sentence']=lines['english_sentence'].apply(lambda x: x.lower())\n",
    "lines['hindi_sentence']=lines['hindi_sentence'].apply(lambda x: x.lower())\n",
    "\n",
    "\n",
    "lines['english_sentence']=lines['english_sentence'].apply(lambda x: re.sub(\"'\", '', x))\n",
    "lines['hindi_sentence']=lines['hindi_sentence'].apply(lambda x: re.sub(\"'\", '', x))\n",
    "\n",
    "exclude = set(string.punctuation) \n",
    "\n",
    "lines['english_sentence']=lines['english_sentence'].apply(lambda x: ''.join(ch for ch in x if ch not in exclude))\n",
    "lines['hindi_sentence']=lines['hindi_sentence'].apply(lambda x: ''.join(ch for ch in x if ch not in exclude))\n",
    "\n",
    "\n",
    "remove_digits = str.maketrans('', '', digits)\n",
    "lines['english_sentence']=lines['english_sentence'].apply(lambda x: x.translate(remove_digits))\n",
    "lines['hindi_sentence']=lines['hindi_sentence'].apply(lambda x: x.translate(remove_digits))\n",
    "\n",
    "lines['hindi_sentence'] = lines['hindi_sentence'].apply(lambda x: re.sub(\"[२३०८१५७९४६]\", \"\", x))\n",
    "\n",
    "\n",
    "lines['english_sentence']=lines['english_sentence'].apply(lambda x: x.strip())\n",
    "lines['hindi_sentence']=lines['hindi_sentence'].apply(lambda x: x.strip())\n",
    "lines['english_sentence']=lines['english_sentence'].apply(lambda x: re.sub(\" +\", \" \", x))\n",
    "lines['hindi_sentence']=lines['hindi_sentence'].apply(lambda x: re.sub(\" +\", \" \", x))\n",
    "\n",
    "\n",
    "lines['hindi_sentence'] = lines['hindi_sentence'].apply(lambda x : 'START_ '+ x + ' _END')\n",
    "\n",
    "\n",
    "\n",
    "all_eng_words=set()\n",
    "for eng in lines['english_sentence']:\n",
    "    for word in eng.split():\n",
    "        if word not in all_eng_words:\n",
    "            all_eng_words.add(word)\n",
    "\n",
    "all_hindi_words=set()\n",
    "for hin in lines['hindi_sentence']:\n",
    "    for word in hin.split():\n",
    "        if word not in all_hindi_words:\n",
    "            all_hindi_words.add(word)\n",
    "\n",
    "\n",
    "len(all_eng_words)\n",
    "\n",
    "len(all_hindi_words)\n",
    "\n",
    "lines['length_eng_sentence']=lines['english_sentence'].apply(lambda x:len(x.split(\" \")))\n",
    "lines['length_hin_sentence']=lines['hindi_sentence'].apply(lambda x:len(x.split(\" \")))\n",
    "\n",
    "lines.head()\n",
    "\n",
    "\n",
    "lines[lines['length_eng_sentence']>30].shape\n",
    "\n",
    "\n",
    "lines=lines[lines['length_eng_sentence']<=20]\n",
    "lines=lines[lines['length_hin_sentence']<=20]\n",
    "\n",
    "\n",
    "lines.shape\n",
    "\n",
    "\n",
    "print(\"maximum length of Hindi Sentence \",max(lines['length_hin_sentence']))\n",
    "print(\"maximum length of English Sentence \",max(lines['length_eng_sentence']))\n",
    "\n",
    "\n",
    "max_length_src=max(lines['length_hin_sentence'])\n",
    "max_length_tar=max(lines['length_eng_sentence'])\n",
    "\n",
    "\n",
    "input_words = sorted(list(all_eng_words))\n",
    "target_words = sorted(list(all_hindi_words))\n",
    "num_encoder_tokens = len(all_eng_words)\n",
    "num_decoder_tokens = len(all_hindi_words)\n",
    "num_encoder_tokens, num_decoder_tokens\n",
    "\n",
    "\n",
    "num_decoder_tokens += 1 \n",
    "\n",
    "\n",
    "input_token_index = dict([(word, i+1) for i, word in enumerate(input_words)])\n",
    "target_token_index = dict([(word, i+1) for i, word in enumerate(target_words)])\n",
    "\n",
    "\n",
    "reverse_input_char_index = dict((i, word) for word, i in input_token_index.items())\n",
    "reverse_target_char_index = dict((i, word) for word, i in target_token_index.items())\n",
    "\n",
    "\n",
    "lines = shuffle(lines)\n",
    "lines.head(10)\n",
    "\n",
    "\n",
    "X, y = lines['english_sentence'], lines['hindi_sentence']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2,random_state=42)\n",
    "X_train.shape, X_test.shape\n",
    "\n",
    "\n",
    "X_train.to_pickle('X_train.pkl')\n",
    "X_test.to_pickle('X_test.pkl')\n",
    "\n",
    "\n",
    "\n",
    "def generate_batch(X = X_train, y = y_train, batch_size = 128):\n",
    "    ''' Generate a batch of data '''\n",
    "    while True:\n",
    "        for j in range(0, len(X), batch_size):\n",
    "            encoder_input_data = np.zeros((batch_size, max_length_src),dtype='float32')\n",
    "            decoder_input_data = np.zeros((batch_size, max_length_tar),dtype='float32')\n",
    "            decoder_target_data = np.zeros((batch_size, max_length_tar, num_decoder_tokens),dtype='float32')\n",
    "            for i, (input_text, target_text) in enumerate(zip(X[j:j+batch_size], y[j:j+batch_size])):\n",
    "                for t, word in enumerate(input_text.split()):\n",
    "                    encoder_input_data[i, t] = input_token_index[word] \n",
    "                for t, word in enumerate(target_text.split()):\n",
    "                    if t<len(target_text.split())-1:\n",
    "                        decoder_input_data[i, t] = target_token_index[word] \n",
    "                    if t>0:\n",
    "          \n",
    "                        decoder_target_data[i, t - 1, target_token_index[word]] = 1.\n",
    "            yield([encoder_input_data, decoder_input_data], decoder_target_data)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "latent_dim=300\n",
    "\n",
    "\n",
    "\n",
    "encoder_inputs = Input(shape=(None,))\n",
    "enc_emb =  Embedding(num_encoder_tokens+1, latent_dim, mask_zero = True)(encoder_inputs)\n",
    "encoder_lstm = LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(enc_emb)\n",
    "\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "\n",
    "\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "dec_emb_layer = Embedding(num_decoder_tokens, latent_dim, mask_zero = True)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_emb,\n",
    "                                     initial_state=encoder_states)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
    "\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "Input Sentence: and theyre different\n",
      "Predicted Output: START_ और वो अलग अलग हैं\n"
     ]
    }
   ],
   "source": [
    "\n",
    "max_length_src = 20\n",
    "\n",
    "\n",
    "\n",
    "input_sentence = \"and theyre different\"\n",
    "\n",
    "input_sequence = preprocess_input_sequence(input_sentence, max_length_src, input_token_index)\n",
    "\n",
    "\n",
    "predicted_output = predict_output(input_sequence, model, max_length_tar, target_token_index, reverse_target_char_index)\n",
    "\n",
    "\n",
    "print(f\"Input Sentence: {input_sentence}\")\n",
    "print(f\"Predicted Output: {predicted_output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "Input Sentence: here was some lawyer or money manager\n",
      "Predicted Output: START_ वो एक वकील या मैनेजर था\n"
     ]
    }
   ],
   "source": [
    "\n",
    "max_length_src = 20\n",
    "\n",
    "\n",
    "\n",
    "input_sentence = \"here was some lawyer or money manager\"\n",
    "\n",
    "\n",
    "input_sequence = preprocess_input_sequence(input_sentence, max_length_src, input_token_index)\n",
    "\n",
    "\n",
    "predicted_output = predict_output(input_sequence, model, max_length_tar, target_token_index, reverse_target_char_index)\n",
    "\n",
    "\n",
    "print(f\"Input Sentence: {input_sentence}\")\n",
    "print(f\"Predicted Output: {predicted_output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "Input Sentence: we just spent and entire week\n",
      "Predicted Output: START_ हमने एक पूरे सप्ताह\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "max_length_src = 20\n",
    "\n",
    "\n",
    "\n",
    "input_sentence = \"we just spent and entire week\"\n",
    "\n",
    "\n",
    "input_sequence = preprocess_input_sequence(input_sentence, max_length_src, input_token_index)\n",
    "\n",
    "\n",
    "predicted_output = predict_output(input_sequence, model, max_length_tar, target_token_index, reverse_target_char_index)\n",
    "\n",
    "print(f\"Input Sentence: {input_sentence}\")\n",
    "print(f\"Predicted Output: {predicted_output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Input Sentence: over the period of an hour\n",
      "Predicted Output: START_ एक घंटे की अवधि में\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "max_length_src = 20\n",
    "\n",
    "\n",
    "\n",
    "input_sentence = \"over the period of an hour\"\n",
    "\n",
    "\n",
    "input_sequence = preprocess_input_sequence(input_sentence, max_length_src, input_token_index)\n",
    "\n",
    "\n",
    "predicted_output = predict_output(input_sequence, model, max_length_tar, target_token_index, reverse_target_char_index)\n",
    "\n",
    "\n",
    "print(f\"Input Sentence: {input_sentence}\")\n",
    "print(f\"Predicted Output: {predicted_output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
